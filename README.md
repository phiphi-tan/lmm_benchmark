# Overall

This README provides a brief overview of this project as well as the intermediate deliverables / timelines.

## Objectives

This internship project aims to develop a comprehensive and effective evaluation benchmark specifically designed for large multimodal models (LMMs). The benchmark will include a diverse set of tasks and datasets across the defence domain, ensuring a holistic assessment of the models’ strength and weaknesses in handling multimodal data in the defence domain.​

## Sub task requirements
An overview of the data requirements and elaboration of the subtasks will be provided in the [data requirements document](/data_requirements.md)

## Notes
- Look into document question answering

## Projected Timeline
> More details regarding each portion will be in the README.md files in the respective directories

The internship has been split into a few different phases, with the projected timeline as represented in parantheses.

### Phase 1: Literature review (2 weeks)
This phase involves literature review on multimodal data curation for evaluation benchmarks.

### Phase 2: Data Curation (2 weeks)
This phase involves the curation of specific data for defence domain.

### Phase 3: Dataset Handling (1 month)
This phase involves automating annotation and filtering of datasets.

Additionally, there can also be further checks implemented to help increase the robustness of datasets used for testing.

### Phase 4: Final Report (1 week)
The final phase involves report writing.

