### Prompt Approaches
The model outputs are notoriously difficult to predict, so part of ensuring an adequate benchmarking performance involves experimenting with different prompt approaches.

Since models are trained on different bases, the more 'chatty' models are harder to prompt to provide just the answer.

At a basic level, a prompt is considered 'successful' if it results in the model providing output in the desired structure. Here are some approaches I've tried

- Completion-prompts
- System-user prompts
